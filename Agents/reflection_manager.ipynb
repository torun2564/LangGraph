{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0be24df-84cd-4876-bcb6-877f9607be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reflection_manager.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reflection_manager.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "from typing import Optional\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from retry import retry\n",
    "\n",
    "openai_smart_model: str = \"gpt-4o\"\n",
    "openai_embedding_model: str = \"text-embedding-3-small\"\n",
    "temperature: float = 0.0\n",
    "default_reflection_db_path: str = \"tmp/reflection_db.json\"\n",
    "\n",
    "\n",
    "class ReflectionJudgment(BaseModel):\n",
    "    needs_retry: bool = Field(\n",
    "        description=\"タスクの実行結果は適切だったと思いますか?あなたの判断を真偽値で示してください。\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        description=\"あなたの判断に対するあなたの自信の度合いを0から1までの小数で示してください。\"\n",
    "    )\n",
    "    reasons: list[str] = Field(\n",
    "        description=\"タスクの実行結果の適切性とそれに対する自信度について、判断に至った理由を簡潔に列挙してください。\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    id: str = Field(description=\"リフレクション内容に一意性を与えるためのID\")\n",
    "    task: str = Field(description=\"ユーザーから与えられたタスクの内容\")\n",
    "    reflection: str = Field(\n",
    "        description=\"このタスクに取り組んだ際のあなたの思考プロセスを振り返ってください。何か改善できる点はありましたか? 次に同様のタスクに取り組む際に、より良い結果を出すための教訓を2〜3文程度で簡潔に述べてください。\"\n",
    "    )\n",
    "    judgment: ReflectionJudgment = Field(description=\"リトライが必要かどうかの判定\")\n",
    "\n",
    "\n",
    "class ReflectionManager:\n",
    "    def __init__(self, file_path: str = default_reflection_db_path):\n",
    "        self.file_path = file_path\n",
    "        self.embeddings = OpenAIEmbeddings(model=openai_embedding_model)\n",
    "        self.reflections: dict[str, Reflection] = {}\n",
    "        self.embeddings_dict: dict[str, list[float]] = {}\n",
    "        self.index = None\n",
    "        self.load_reflections()\n",
    "\n",
    "    def load_reflections(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "                for item in data:\n",
    "                    reflection = Reflection(**item[\"reflection\"])\n",
    "                    self.reflections[reflection.id] = reflection\n",
    "                    self.embeddings_dict[reflection.id] = item[\"embedding\"]\n",
    "\n",
    "            if self.reflections:\n",
    "                embeddings = list(self.embeddings_dict.values())\n",
    "                self.index = faiss.IndexFlatL2(len(embeddings[0]))\n",
    "                self.index.add(np.array(embeddings).astype(\"float32\"))\n",
    "\n",
    "    def save_reflection(self, reflection: Reflection) -> str:\n",
    "        reflection.id = str(uuid.uuid4())\n",
    "        reflection_id = reflection.id\n",
    "        self.reflections[reflection_id] = reflection\n",
    "        embedding = self.embeddings.embed_query(reflection.reflection)\n",
    "        self.embeddings_dict[reflection_id] = embedding\n",
    "\n",
    "        if self.index is None:\n",
    "            self.index = faiss.IndexFlatL2(len(embedding))\n",
    "        self.index.add(np.array([embedding]).astype(\"float32\"))\n",
    "\n",
    "        with open(self.file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(\n",
    "                [\n",
    "                    {\"reflection\": reflection.dict(), \"embedding\": embedding}\n",
    "                    for reflection, embedding in zip(\n",
    "                        self.reflections.values(), self.embeddings_dict.values()\n",
    "                    )\n",
    "                ],\n",
    "                file,\n",
    "                ensure_ascii=False,\n",
    "                indent=4,\n",
    "            )\n",
    "\n",
    "        return reflection_id\n",
    "\n",
    "    def get_reflection(self, reflection_id: str) -> Optional[Reflection]:\n",
    "        return self.reflections.get(reflection_id)\n",
    "\n",
    "    def get_relevant_reflections(self, query: str, k: int = 3) -> list[Reflection]:\n",
    "        if not self.reflections or self.index is None:\n",
    "            return []\n",
    "\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        try:\n",
    "            D, I = self.index.search(\n",
    "                np.array([query_embedding]).astype(\"float32\"),\n",
    "                min(k, len(self.reflections)),\n",
    "            )\n",
    "            reflection_ids = list(self.reflections.keys())\n",
    "            return [\n",
    "                self.reflections[reflection_ids[i]]\n",
    "                for i in I[0]\n",
    "                if i < len(reflection_ids)\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error during reflection search: {e}\")\n",
    "            return []\n",
    "    \n",
    "\n",
    "class TaskReflector:\n",
    "    def __init__(self, llm: BaseChatModel, reflection_manager: ReflectionManager):\n",
    "        self.llm = llm.with_structured_output(Reflection)\n",
    "        self.reflection_manager = reflection_manager\n",
    "\n",
    "    def run(self, task: str, result: str) -> Reflection:\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"与えられたタスクの内容:\\n{task}\\n\\n\"\n",
    "            \"タスクを実行した結果:\\n{result}\\n\\n\"\n",
    "            \"あなたは高度な推論能力を持つAIエージェントです。上記のタスクを実行した結果を分析し、このタスクに対するあなたの取り組みが適切だったかどうかを内省してください。\\n\"\n",
    "            \"以下の項目に沿って、リフレクションの内容を出力してください。\\n\\n\"\n",
    "            \"リフレクション:\\n\"\n",
    "            \"このタスクに取り組んだ際のあなたの思考プロセスや方法を振り返ってください。何か改善できる点はありましたか?\\n\"\n",
    "            \"次に同様のタスクに取り組む際に、より良い結果を出すための教訓を2〜3文程度で簡潔に述べてください。\\n\\n\"\n",
    "            \"判定:\\n\"\n",
    "            \"- 結果の適切性: タスクの実行結果は適切だったと思いますか?あなたの判断を真偽値で示してください。\\n\"\n",
    "            \"- 判定の自信度: 上記の判断に対するあなたの自信の度合いを0から1までの小数で示してください。\\n\"\n",
    "            \"- 判定の理由: タスクの実行結果の適切性とそれに対する自信度について、判断に至った理由を簡潔に列挙してください。\\n\\n\"\n",
    "            \"出力は必ず日本語で行ってください。\\n\\n\"\n",
    "            \"Tips: Make sure to answer in the correct format.\"\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "\n",
    "        @retry(tries=5)\n",
    "        def invoke_chain() -> Reflection:\n",
    "            return chain.invoke({\"task\": task, \"result\": result})\n",
    "\n",
    "        reflection = invoke_chain()\n",
    "        reflection_id = self.reflection_manager.save_reflection(reflection)\n",
    "        reflection.id = reflection_id\n",
    "\n",
    "        return reflection\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb8bca-0112-4f55-b269-d4c59743bc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d80242-c30a-4669-9bb9-ee853332efa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
