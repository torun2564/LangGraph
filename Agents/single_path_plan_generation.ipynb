{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dd0f0a-b349-40a3-b06e-f60bf3b0ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting single_path_plan_generation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile single_path_plan_generation.py\n",
    "import operator\n",
    "from datetime import datetime\n",
    "from typing import Annotated, Any\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DecomposedTasks(BaseModel):\n",
    "    values: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        min_items=3,\n",
    "        max_items=5,\n",
    "        description=\"3~5個に分解されたタスク\",\n",
    "    )\n",
    "\n",
    "class SinglePathPlanGenerationState(BaseModel):\n",
    "    query: str = Field(..., description=\"ユーザーが入力したクエリ\")\n",
    "    optimized_goal: str = Field(default=\"\", description=\"最適化された目標\")\n",
    "    optimized_response: str = Field(\n",
    "        default=\"\", description=\"最適化されたレスポンス定義\"\n",
    "    )\n",
    "    tasks: list[str] = Field(default_factory=list, description=\"実行するタスクのリスト\")\n",
    "    current_task_index: int = Field(default=0, description=\"現在実行中のタスクの番号\")\n",
    "    results: Annotated[list[str], operator.add] = Field(\n",
    "        default_factory=list, description=\"実行済みタスクの結果リスト\"\n",
    "    )\n",
    "    final_output: str = Field(default=\"\", description=\"最終的な出力結果\")\n",
    "\n",
    "class QueryDecomposer:\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        self.current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    def run(self, query: str) -> DecomposedTasks:\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            f\"CURRENT_DATE: {self.current_date}\\n\"\n",
    "            \"-----\\n\"\n",
    "            \"タスク: 与えられた目標を具体的で実行可能なタスクに分解してください。\\n\"\n",
    "            \"要件:\\n\"\n",
    "            \"1. 以下の行動だけで目標を達成すること。決して指定された以外の行動をとらないこと。\\n\"\n",
    "            \"   - インターネットを利用して、目標を達成するための調査を行う。\\n\"\n",
    "            \"2. 各タスクは具体的かつ詳細に記載されており、単独で実行ならびに検証可能な情報を含めること。一切抽象的な表現を含まないこと。\\n\"\n",
    "            \"3. タスクは実行可能な順序でリスト化すること。\\n\"\n",
    "            \"4. タスクは日本語で出力すること。\\n\"\n",
    "            \"目標: {query}\"\n",
    "        )\n",
    "        chain = prompt | self.llm.with_structured_output(DecomposedTasks)\n",
    "        return chain.invoke({\"query\": query})\n",
    "\n",
    "\n",
    "class TaskExecutor:\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        self.tools = [TavilySearchResults(max_results=3)]\n",
    "\n",
    "    def run(self, task: str) -> str:\n",
    "        agent = create_react_agent(self.llm, self.tools)\n",
    "        result = agent.invoke(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        (\n",
    "                            \"次のタスクを実行し、詳細な回答を提供してください。\\n\\n\"\n",
    "                            f\"タスク: {task}\\n\\n\"\n",
    "                            \"要件:\\n\"\n",
    "                            \"1. 必要に応じて提供されたツールを使用してください。\\n\"\n",
    "                            \"2. 実行は徹底的かつ包括的に行ってください。\\n\"\n",
    "                            \"3. 可能な限り具体的な事実やデータを提供してください。\\n\"\n",
    "                            \"4. 発見した内容を明確に要約してください。\\n\"\n",
    "                        ),\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "class ResultAggregator:\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "\n",
    "    def run(self, query: str, response_definition: str, results: list[str]) -> str:\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"与えられた目標:\\n{query}\\n\\n\"\n",
    "            \"調査結果:\\n{results}\\n\\n\"\n",
    "            \"与えられた目標に対し、調査結果を用いて、以下の指示に基づいてレスポンスを生成してください。\\n\"\n",
    "            \"{response_definition}\"\n",
    "        )\n",
    "        results_str = \"\\n\\n\".join(\n",
    "            f\"Info {i+1}:\\n{result}\" for i, result in enumerate(results)\n",
    "        )\n",
    "        chain = prompt | self.llm | StrOutputParser()\n",
    "        return chain.invoke(\n",
    "            {\n",
    "                \"query\": query,\n",
    "                \"results\": results_str,\n",
    "                \"response_definition\": response_definition,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class SinglePathPlanGeneration:\n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.passive_goal_creator = PassiveGoalCreator(llm=llm)\n",
    "        self.prompt_optimizer = PromptOptimizer(llm=llm)\n",
    "        self.response_optimizer = ResponseOptimizer(llm=llm)\n",
    "        self.query_decomposer = QueryDecomposer(llm=llm)\n",
    "        self.task_executor = TaskExecutor(llm=llm)\n",
    "        self.result_aggregator = ResultAggregator(llm=llm)\n",
    "        self.graph = self._create_graph()\n",
    "\n",
    "    def _create_graph(self) -> StateGraph:\n",
    "        graph = StateGraph(SinglePathPlanGenerationState)\n",
    "        graph.add_node(\"goal_setting\", self._goal_setting)\n",
    "        graph.add_node(\"decompose_query\", self._decompose_query)\n",
    "        graph.add_node(\"execute_task\", self._execute_task)\n",
    "        graph.add_node(\"aggregate_results\", self._aggregate_results)\n",
    "        graph.set_entry_point(\"goal_setting\")\n",
    "        graph.add_edge(\"goal_setting\", \"decompose_query\")\n",
    "        graph.add_edge(\"decompose_query\", \"execute_task\")\n",
    "        graph.add_conditional_edges(\n",
    "            \"execute_task\",\n",
    "            lambda state: state.current_task_index < len(state.tasks),\n",
    "            {True: \"execute_task\", False: \"aggregate_results\"},\n",
    "        )\n",
    "        graph.add_edge(\"aggregate_results\", END)\n",
    "        return graph.compile()\n",
    "\n",
    "    def _goal_setting(self, state: SinglePathPlanGenerationState) -> dict[str, Any]:\n",
    "        # プロンプト最適化\n",
    "        goal: Goal = self.passive_goal_creator.run(query=state.query)\n",
    "        optimized_goal: OptimizedGoal = self.prompt_optimizer.run(query=goal.text)\n",
    "        # レスポンス最適化\n",
    "        optimized_response: str = self.response_optimizer.run(query=optimized_goal.text)\n",
    "        return {\n",
    "            \"optimized_goal\": optimized_goal.text,\n",
    "            \"optimized_response\": optimized_response,\n",
    "        }\n",
    "\n",
    "    def _decompose_query(self, state: SinglePathPlanGenerationState) -> dict[str, Any]:\n",
    "        decomposed_tasks: DecomposedTasks = self.query_decomposer.run(\n",
    "            query=state.optimized_goal\n",
    "        )\n",
    "        return {\"tasks\": decomposed_tasks.values}\n",
    "\n",
    "    def _execute_task(self, state: SinglePathPlanGenerationState) -> dict[str, Any]:\n",
    "        current_task = state.tasks[state.current_task_index]\n",
    "        result = self.task_executor.run(task=current_task)\n",
    "        return {\n",
    "            \"results\": [result],\n",
    "            \"current_task_index\": state.current_task_index + 1,\n",
    "        }\n",
    "\n",
    "    def _aggregate_results(\n",
    "        self, state: SinglePathPlanGenerationState\n",
    "    ) -> dict[str, Any]:\n",
    "        final_output = self.result_aggregator.run(\n",
    "            query=state.optimized_goal,\n",
    "            response_definition=state.optimized_response,\n",
    "            results=state.results,\n",
    "        )\n",
    "        return {\"final_output\": final_output}\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        initial_state = SinglePathPlanGenerationState(query=query)\n",
    "        final_state = self.graph.invoke(initial_state, {\"recursion_limit\": 1000})\n",
    "        return final_state.get(\"final_output\", \"Failed to generate a final response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ed8c3-6f22-4cb1-8e86-1f97e2682a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
